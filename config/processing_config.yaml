# Processing Configuration
# Contains limits and thresholds for data processing

limits:
  # Maximum characters to extract from job text for single job classification
  # Set to 25,000 to handle 99%+ of jobs without truncation
  job_text_single_job: 25000

  # Maximum characters per job in batch classification
  # Set to 25,000 - same as single job. Each batch is a separate request,
  # so there's no reason to truncate more aggressively. Zero truncation is the goal!
  job_text_batch: 25000

  # Maximum characters per job in mega-batch classification
  # Set to 25,000 for zero truncation (handles ~150 jobs per mega-batch with 1M token context)
  # If you fetch more than 150 jobs, multiple mega-batches will be created automatically
  job_text_mega_batch: 25000

  # Maximum jobs per mega-batch (calculated based on 1M token context window)
  # Conservative limit: 100 jobs uses ~37% of context (large safety margin)
  # Based on real API tests: 7 chars/token for German job descriptions
  # Larger searches will be automatically split into multiple mega-batches
  max_jobs_per_mega_batch: 100
